# LLM-From-Scratch-To-Advanced-RL-Techniques
Build an end-to-end Large Language Model from scratch: implement transformers, train a tiny LLM, modernize with RoPE and RMSNorm, scale training, add Mixture-of-Experts, perform Supervised Fine-Tuning, train a Reward Model, and apply RLHF with PPO and also RLHF with GRPO for alignment and reinforcement learning.
